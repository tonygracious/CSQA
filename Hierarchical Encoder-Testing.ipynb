{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    res_path = './results'\n",
    "    model_path = './models'\n",
    "    epoch  = 20\n",
    "    patience = -1\n",
    "    teacher = False\n",
    "    bidi = False\n",
    "    test = False\n",
    "    shrd_dec_emb = False \n",
    "    btstrp  = None \n",
    "    lm = False \n",
    "    toy = False \n",
    "    pretty = False \n",
    "    mmi = False\n",
    "    seq2seq = False \n",
    "    drp = 0.3\n",
    "    num_lyr = 1\n",
    "    lr = 0.0001\n",
    "    bt_siz = 64\n",
    "    beam = 1\n",
    "    vocab_size = 50005 \n",
    "    response_vocab_size = 32149\n",
    "    emb_size = 300\n",
    "    hid_size = 128\n",
    "    ut_hid_size = 128\n",
    "    ses_hid_size = 256\n",
    "    dec_hid_size = 256\n",
    "    kb_embed_size = 100\n",
    "    kb_size = 9274341\n",
    "    kb_relations_size= 571\n",
    "    use_embed = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ent_embed = np.load('transe_dir/ent_embed.pkl.npy')\n",
    "rel_embed = np.load('transe_dir/rel_embed.pkl.npy')\n",
    "\n",
    "new_row = np.zeros((1,100), dtype=np.float32)\n",
    "    \n",
    "ent_embed = np.vstack([new_row, ent_embed]) # corr. to <pad_kb>\n",
    "ent_embed = np.vstack([new_row, ent_embed]) # corr. to <nkb>\n",
    "\n",
    "rel_embed = np.vstack([new_row, rel_embed]) # corr. to <pad_kb>\n",
    "rel_embed = np.vstack([new_row, rel_embed]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_processing(mini_batch):\n",
    "    mem_size = len(mini_batch[0][6].split('|'))\n",
    "    if mem_size > 10000 :\n",
    "        mem_size =  10000\n",
    "    u1_text = np.array([s[0][0] for s in mini_batch])\n",
    "    u1_kb   = np.array([s[1][0] for s in mini_batch])\n",
    "    u2_text = np.array([s[0][1] for s in mini_batch] )\n",
    "    u2_kb   = np.array([s[1][1] for s in mini_batch])\n",
    "    target_kb = np.array([s[2] for s in mini_batch])\n",
    "    target_utterance = np.array([s[3] for s in mini_batch])\n",
    "    cand_ent =  [ [int(i) for i in s[6].split('|')] for s in mini_batch]\n",
    "    cand_ent =  [ s[:-1][:mem_size-1]+[1]  for s in cand_ent]\n",
    "    cand_ent =  np.array([ s + [0]*(mem_size-len(s)) for s in cand_ent])\n",
    "    \n",
    "    cand_rel =  [ [int(i) for i in s[7].split('|')] for s in mini_batch]\n",
    "    cand_rel =  [ s[:-1][:mem_size-1]+[1]  for s in cand_rel]\n",
    "    cand_rel =  np.array([ s + [0]*(mem_size - len(s)) for s in cand_rel])\n",
    "    \n",
    "    cand_val =  [ [int(i) for i in s[8].split('|')] for s in mini_batch]\n",
    "    cand_val =  [ s[:-1][:mem_size-1]+[1]  for s in cand_val]\n",
    "    cand_val =  np.array([s + [0]*(mem_size-len(s)) for s in cand_val])\n",
    "    '''\n",
    "    mem_weights = ((cand_val!=0) * (cand_val!=1) ).astype(int)\n",
    "    \n",
    "   \n",
    "    labels = []\n",
    "    candidates = []\n",
    "    for i in range(64):\n",
    "        positive_samples_i =list( set(target_kb[i])-{0})\n",
    "        labels_i = [1]*len(positive_samples_i)\n",
    "        negative_samples_i = list(set(cand_val[i])-(set(target_kb[i])-{0}) )\n",
    "        if len(negative_samples_i) > 0:\n",
    "            negative_samples_subset_i  = list( np.random.choice(negative_samples_i,20 - len(labels_i)) )\n",
    "        else :\n",
    "            negative_samples_subset_i =[]\n",
    "\n",
    "        labels_i = labels_i + [0] *(20 - len(labels_i))\n",
    "        candidates_i = positive_samples_i + negative_samples_subset_i\n",
    "        candidates_i = candidates_i + (20-len(candidates_i)) *[0]\n",
    "\n",
    "        labels.append(labels_i)\n",
    "        candidates.append( candidates_i )\n",
    "    \n",
    "    c = np.array(labels)\n",
    "    candidates_pred = np.array(candidates)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    b , l = cand_val.shape\n",
    "    c = np.zeros((b, l))\n",
    "    for i in range(b):\n",
    "        for j in range(l):\n",
    "            c[i,j] = int( (cand_val[i,j] in target_kb[i]) and cand_val[i,j] != 0) \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(u1_text, u1_kb, u2_text, u2_kb, target_kb, target_utterance,  cand_ent, cand_rel, cand_val,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_candidates(t):\n",
    "    n_samples = len(t)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        cand = t[i][6].split('|')\n",
    "        n_cand = len(cand)\n",
    "        if n_cand  < 10:\n",
    "            t[i][6] = '|'.join( cand + ['0']*(10-n_cand))\n",
    "            cand = t[i][7].split('|')\n",
    "            t[i][7] = '|'.join( cand + ['0']*(10-n_cand))\n",
    "            cand = t[i][8].split('|')\n",
    "            t[i][8] = '|'.join( cand + ['0']*(10-n_cand))\n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tony/miniconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model_ = model(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.load_state_dict(torch.load('train.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (enc): UtteranceEncoder(\n",
       "    (drop): Dropout(p=0.3)\n",
       "    (embed_vocab): Embedding(50005, 300)\n",
       "    (rnn): GRU(400, 128, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (kvmlookup): KVMemoryReader(\n",
       "    (C): Linear(in_features=128, out_features=200, bias=True)\n",
       "    (R): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (softmax): Softmax()\n",
       "    (drop): Dropout(p=0.3)\n",
       "  )\n",
       "  (inter_utter_encoder): InterUtteranceEncoder(\n",
       "    (rnn): GRU(128, 128, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (drop): Dropout(p=0.3)\n",
       "    (tanh): Tanh()\n",
       "    (embed_in): Embedding(32149, 300)\n",
       "    (embed_out): Linear(in_features=300, out_features=32149, bias=False)\n",
       "    (rnn): GRU(300, 256, batch_first=True, dropout=0.3)\n",
       "    (ses_to_dec): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dec_inf): Linear(in_features=256, out_features=600, bias=False)\n",
       "    (ses_inf): Linear(in_features=256, out_features=600, bias=False)\n",
       "    (emb_inf): Linear(in_features=300, out_features=600, bias=True)\n",
       "  )\n",
       "  (kg_predict): KG_embedding(\n",
       "    (B): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_files=[\"dump/test_preprocessed/\"+x for x in os.listdir(\"/home/tony/QA/dump/test_preprocessed/\") if x.startswith('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dump/test_preprocessed/test_data_file_comparative_count.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_logical.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_quantitative.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_comparative.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_simple.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_quantitative_count.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_verify.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dump/test_preprocessed/test_data_file_simple.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_logical.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_quantitative.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_comparative.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kb = [testing_files[-3], testing_files[1], testing_files[2], testing_files[3]]\n",
    "test_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dump/test_preprocessed/test_data_file_comparative_count.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_quantitative_count.pkl',\n",
       " 'dump/test_preprocessed/test_data_file_verify.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word = [testing_files[0], testing_files[-2], testing_files[-1]]\n",
    "test_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pkl.load(open(testing_files[-3], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ent_map = pkl.load(open('transe_dir/id_rel_map.pickle', 'rb'))\n",
    "ent_id_map = dict( [(i[1], i[0]+2)for i in id_ent_map.items()] )\n",
    "ent_id_map['nkb'] = 1\n",
    "ent_id_map['pad'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.dec.teacher_forcing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.dec.tc_ratio = -100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (enc): UtteranceEncoder(\n",
       "    (drop): Dropout(p=0.3)\n",
       "    (embed_vocab): Embedding(50005, 300)\n",
       "    (rnn): GRU(400, 128, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (kvmlookup): KVMemoryReader(\n",
       "    (C): Linear(in_features=128, out_features=200, bias=True)\n",
       "    (R): Linear(in_features=100, out_features=128, bias=True)\n",
       "    (softmax): Softmax()\n",
       "    (drop): Dropout(p=0.3)\n",
       "  )\n",
       "  (inter_utter_encoder): InterUtteranceEncoder(\n",
       "    (rnn): GRU(128, 128, batch_first=True, dropout=0.3)\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (drop): Dropout(p=0.3)\n",
       "    (tanh): Tanh()\n",
       "    (embed_in): Embedding(32149, 300)\n",
       "    (embed_out): Linear(in_features=300, out_features=32149, bias=False)\n",
       "    (rnn): GRU(300, 256, batch_first=True, dropout=0.3)\n",
       "    (ses_to_dec): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dec_inf): Linear(in_features=256, out_features=600, bias=False)\n",
       "    (ses_inf): Linear(in_features=256, out_features=600, bias=False)\n",
       "    (emb_inf): Linear(in_features=300, out_features=600, bias=True)\n",
       "  )\n",
       "  (kg_predict): KG_embedding(\n",
       "    (B): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d679dcf1825e4794aaa1d3991111197c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=235), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f5e48688e442958d946dd88b824c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=352), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f208539d44c4f92bf177c491cac6052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=145), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07dc9de92cfb44f1a752d9e4ea0729ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=239), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8698263b009e4b56a63365cb603283e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1282), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2050be324b0d49dcbe02b7f1c140d617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a4f5c762f4e87b87f924ddfafeb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=418), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5f0ad19156e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtarget_utterance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_utterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mcand_ent_embed\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcand_ent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mcand_rel_embed\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcand_rel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mcand_val_embed\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcand_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_rec = 0\n",
    "count_prec  = 0\n",
    "recall_ = 0\n",
    "precision_ = 0\n",
    "count_accuracy = 0\n",
    "accuracy_ = 0 \n",
    "for file in testing_files:\n",
    "        t = pkl.load(open(file, 'rb'))\n",
    "        t = padded_candidates(t)\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(t)\n",
    "        n_batches = (len(t)//64)\n",
    "        t = sorted(t, key = lambda x : -1 *len(x[6].split('|')))\n",
    "        \n",
    "        for i in tqdm_notebook(range(0, n_batches+1)):\n",
    "            \n",
    "            minibatch = t[ (i) * 64 : (i+1) *64]\n",
    "            \n",
    "            u1_text, u1_kb, u2_text, u2_kb, target_kb, target_utterance,\\\n",
    "                                cand_ent, cand_rel, cand_val, c = mini_batch_processing(minibatch)\n",
    "            \n",
    "            \n",
    "            u1_text = np.flip(u1_text, axis = 1).copy()\n",
    "            u1_kb = np.flip(u1_kb, axis = 1).copy()\n",
    "\n",
    "            u2_text = np.flip(u2_text, axis = 1).copy()\n",
    "            u2_kb = np.flip(u2_kb, axis = 1).copy()\n",
    "\n",
    "            u1_text = torch.LongTensor(u1_text).cuda()\n",
    "            u2_text = torch.LongTensor(u2_text).cuda()\n",
    "\n",
    "            u1_kb = torch.FloatTensor(ent_embed[u1_kb]).cuda()\n",
    "            u2_kb = torch.FloatTensor(ent_embed[u2_kb]).cuda()\n",
    "            system_utterance = target_utterance\n",
    "            target_utterance = torch.LongTensor(target_utterance).cuda()\n",
    "            \n",
    "            cand_ent_embed  = torch.FloatTensor(ent_embed[cand_ent]).cuda()\n",
    "            cand_rel_embed  = torch.FloatTensor(rel_embed[cand_rel]).cuda()\n",
    "            cand_val_embed  = torch.FloatTensor(ent_embed[cand_val]).cuda()\n",
    "            cand_pred_embed = torch.FloatTensor(ent_embed[cand_val]).cuda()\n",
    "\n",
    "            pred = model_(u1_text, u1_kb, u2_text, u2_kb,target_utterance,\\\n",
    "                            cand_ent_embed, cand_rel_embed, cand_val_embed)\n",
    "            \n",
    "            pred_text = pred[0]\n",
    "            _, pos = torch.topk(pred_text,1, dim=2)\n",
    "            pos.squeeze_(dim=2) \n",
    "            pos = np.array(pos.tolist())\n",
    "            \n",
    "            if file in test_kb :\n",
    "                for s_i in range(pos.shape[0]):\n",
    "                    n_kb = sum(pos[s_i]==4)\n",
    "                    cand_pred = set([])\n",
    "                    if n_kb:\n",
    "                        _, cand_pred = torch.topk(pred[1][s_i], n_kb)\n",
    "                        cand_pred =set(cand_val[s_i][cand_pred.tolist()])\n",
    "\n",
    "                    true_kbs = set( minibatch[s_i][-1].split('|') )\n",
    "                    true_kbs = set([ent_id_map[i] for i in true_kbs if i in ent_id_map ])\n",
    "\n",
    "                    if len(true_kbs) > 0 :\n",
    "                        recall_  = recall_ + len(true_kbs & cand_pred)* 1./ len(true_kbs)\n",
    "                        count_rec = count_rec + 1\n",
    "                    if n_kb :\n",
    "                        precision_ = precision_ + len(true_kbs & cand_pred)* 1./ ( len(cand_pred) )\n",
    "                        count_prec = count_prec + 1\n",
    "                    elif n_kb == 0 and len(true_kbs)> 0 :\n",
    "                        count_prec = count_prec + 1\n",
    "\n",
    "            else :\n",
    "                \n",
    "                accuracy_ = accuracy_ + (system_utterance[:, 1] == pos[:, 0]).sum()\n",
    "                count_accuracy = count_accuracy + pos.shape[0]\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cand_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09953776662599748"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_/count_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11737840805424363"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_ / count_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44243"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
